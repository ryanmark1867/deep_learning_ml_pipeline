# config file for pipeline_script.py
ENDPOINT_NAME : 'klrealestate'
# from https://cloud.google.com/vertex-ai/docs/training/pre-built-containers
train_image : "us-docker.pkg.dev/vertex-ai/training/tf-cpu.2-9:latest"
# from https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers
deploy_image : "us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-9:latest"
config_file_path : "model_training_config.yml"
# Google Cloud Storage file containing the config settings for the training script

script_path : "model_training_keras_preprocessing.py"
machine_type : 'n1-standard-4'
machine_type_deploy : 'n1-standard-2'
# project details
project_id : 'first-project-ml-tabular'
region : 'us-central1'
dataset_id : '2901415472631119872'
# bucket locations
staging_path : "gs://second-project-ml-tabular-bucket/staging/"
config_bucket_path : "gs://third-project-ml-tabular-bucket/training_scripts/model_training_config.yml"
# training specs - these supercede the splits in the model training config
training_fraction_split : 0.8
validation_fraction_split : 0.1
test_fraction_split : 0.1

deploy_model: TRUE